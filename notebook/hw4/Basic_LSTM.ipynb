{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, LeakyReLU, Dropout, Conv1D, MaxPooling1D, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label_data_path = '/home/csdai/hw4_data/training_label.txt'\n",
    "training_label_index_data_path = '/home/csdai/hw4_data/training_label_index.txt'\n",
    "nolabel_data_path = '/home/csdai/hw4_data/training_nolabel.txt'\n",
    "nolabel_index_data_path = '/home/csdai/hw4_data/training_nolabel_index.txt'\n",
    "testing_data_path = '/home/csdai/hw4_data/testing_data.txt'\n",
    "labeled_index_data_path = '/home/csdai/hw4_data/labeled_index.txt'\n",
    "dict_path = '/home/csdai/hw4_data/dict.txt'\n",
    "testing_data_index_path = '/home/csdai/hw4_data/testing_data_index.txt'\n",
    "answer_path = '/home/csdai/hw4_data/answer.txt'\n",
    "model_path = '/home/csdai/hw4_data/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(training_label_index_data_path):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(training_label_index_data_path, 'r') as train_data:\n",
    "        for line in train_data:\n",
    "            label, text = line.strip().split(',')\n",
    "            x.append(list(map(int, text.split(' '))))\n",
    "            y.append(int(label))\n",
    "    return x, y\n",
    "\n",
    "def read_test_data(testing_data_index_path):\n",
    "    x = []\n",
    "    with open(testing_data_index_path, 'r') as test_data:\n",
    "        for line in test_data:\n",
    "            index, text = line.strip().split(',')\n",
    "            x.append(list(map(int, text.split(' '))))\n",
    "    return x\n",
    "\n",
    "def write_answer(pred, answer_path):\n",
    "    if os.path.isfile(answer_path):\n",
    "        os.remove(answer_path)\n",
    "    with open(answer_path, 'a') as answer:\n",
    "        index = 0\n",
    "        answer.write('id,label\\r\\n')\n",
    "        for score in pred:\n",
    "            if score >= 0.5:\n",
    "                answer.write(str(index) +',1\\r\\n')\n",
    "            else:\n",
    "                answer.write(str(index) +',0\\r\\n')\n",
    "            index += 1 \n",
    "\n",
    "def read_nolabel_data(nolabel_index_data_path):\n",
    "    x = []\n",
    "    with open(nolabel_index_data_path, 'r') as train_data:\n",
    "        for line in train_data:\n",
    "            x.append(list(map(int, line.strip().split(' '))))\n",
    "    return x\n",
    "\n",
    "def read_labeled_data(labeled_index_data_path, threshold):\n",
    "    x = []\n",
    "    y = []\n",
    "    count_1 = 0\n",
    "    count_0 = 0\n",
    "    with open(labeled_index_data_path, 'r') as labeled_data:\n",
    "        for line in labeled_data:\n",
    "            label, text = line.strip().split(',')\n",
    "            if float(label) >= threshold:\n",
    "                label = 1\n",
    "                x.append(list(map(int, text.split(' '))))\n",
    "                y.append(int(label))\n",
    "                count_1 += 1\n",
    "            elif float(label) <= 1 - threshold:\n",
    "                label = 0\n",
    "                x.append(list(map(int, text.split(' '))))\n",
    "                y.append(int(label))\n",
    "                count_0 += 1\n",
    "    print(count_1, count_0)\n",
    "    return x, y\n",
    "\n",
    "def generate_label(pred, x, labeled_index_data_path):\n",
    "    if os.path.isfile(labeled_index_data_path):\n",
    "        os.remove(labeled_index_data_path)\n",
    "    with open(labeled_index_data_path, 'a') as labeled_data:\n",
    "        for cntr in range(len(pred)):\n",
    "            s = ''\n",
    "            for ele in x[cntr]:\n",
    "                s += str(ele) +' '\n",
    "            labeled_data.write(str(pred[cntr][0]) +','+ s.strip() +'\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 30\n",
    "val_cut = 50000\n",
    "x_train, y_train = read_train_data(training_label_index_data_path)\n",
    "x_labeled, y_labeled = read_labeled_data(labeled_index_data_path, 0.95)\n",
    "x_train = x_train + x_labeled\n",
    "y_train = y_train + y_labeled\n",
    "x_val, y_val = x_train[:val_cut], y_train[:val_cut]\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=max_review_length, padding='post')\n",
    "#x_train = x_train[val_cut:]\n",
    "#y_train = y_train[val_cut:]\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_review_length, padding='post')\n",
    "x_test = read_test_data(testing_data_index_path)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_review_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    model = Sequential()\n",
    "    embedding_vecor_length = 256\n",
    "    max_word = 15000\n",
    "    model.add(Embedding(max_word, embedding_vecor_length, input_length=max_review_length, mask_zero=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def model_2():\n",
    "    model = Sequential()\n",
    "    embedding_vecor_length = 512\n",
    "    max_word = 15000\n",
    "    model.add(Embedding(max_word, embedding_vecor_length, input_length=max_review_length, mask_zero=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(512, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def model_3():\n",
    "    model = Sequential()\n",
    "    embedding_vecor_length = 100\n",
    "    max_word = 15000\n",
    "    model.add(Embedding(max_word, embedding_vecor_length, input_length=max_review_length))\n",
    "    model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def model_4():\n",
    "    model = Sequential()\n",
    "    embedding_vecor_length = 256\n",
    "    max_word = 15000\n",
    "    model.add(Embedding(max_word, embedding_vecor_length, input_length=max_review_length))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_3()\n",
    "epoch = 1\n",
    "model.fit(x_train, y_train, epochs=epoch, batch_size=2048, validation_data=(x_val, y_val))\n",
    "model_temp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_7'\n",
    "model.save(model_path + model_name +'.h5')\n",
    "def write_info(model_name, summary):\n",
    "    with open(model_path + model_name +'_info', 'w') as model_info:\n",
    "        model_info.write('val_acc: 0.8704\\r\\n')\n",
    "        model_info.write(summary)\n",
    "        \n",
    "write_info(model_name, str(model.to_json()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "write_answer(pred, answer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nolabel = read_nolabel_data(nolabel_index_data_path)\n",
    "x = x_nolabel\n",
    "x_nolabel = sequence.pad_sequences(x_nolabel, maxlen=max_review_length, padding='post')\n",
    "pred = model.predict(x_nolabel)\n",
    "generate_label(pred, x, labeled_index_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
