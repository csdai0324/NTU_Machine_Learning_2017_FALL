{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LeakyReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label_data_path = '/home/csdai/hw4_data/training_label.txt'\n",
    "training_label_index_data_path = '/home/csdai/hw4_data/training_label_index.txt'\n",
    "nolabel_data_path = '/home/csdai/hw4_data/training_nolabel.txt'\n",
    "nolabel_index_data_path = '/home/csdai/hw4_data/training_nolabel_index.txt'\n",
    "testing_data_path = '/home/csdai/hw4_data/testing_data.txt'\n",
    "labeled_index_data_path = '/home/csdai/hw4_data/labeled_index.txt'\n",
    "dict_path = '/home/csdai/hw4_data/dict.txt'\n",
    "testing_data_index_path = '/home/csdai/hw4_data/testing_data_index.txt'\n",
    "answer_path = '/home/csdai/hw4_data/answer.txt'\n",
    "bow_answer_path = '/home/csdai/hw4_data/bow_answer.txt'\n",
    "model_path = '/home/csdai/hw4_data/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(training_label_index_data_path):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(training_label_index_data_path, 'r') as train_data:\n",
    "        for line in train_data:\n",
    "            label, text = line.strip().split(',')\n",
    "            x.append(list(map(int, text.split(' '))))\n",
    "            y.append(int(label))\n",
    "    return x, y\n",
    "\n",
    "def read_test_data(testing_data_index_path):\n",
    "    x = []\n",
    "    with open(testing_data_index_path, 'r') as test_data:\n",
    "        for line in test_data:\n",
    "            index, text = line.strip().split(',')\n",
    "            x.append(list(map(int, text.split(' '))))\n",
    "    return x\n",
    "\n",
    "def write_answer(pred, answer_path):\n",
    "    if os.path.isfile(answer_path):\n",
    "        os.remove(answer_path)\n",
    "    with open(answer_path, 'a') as answer:\n",
    "        index = 0\n",
    "        answer.write('id,label\\r\\n')\n",
    "        for score in pred:\n",
    "            if score >= 0.5:\n",
    "                answer.write(str(index) +',1\\r\\n')\n",
    "            else:\n",
    "                answer.write(str(index) +',0\\r\\n')\n",
    "            index += 1 \n",
    "\n",
    "def read_nolabel_data(nolabel_index_data_path):\n",
    "    x = []\n",
    "    with open(nolabel_index_data_path, 'r') as train_data:\n",
    "        for line in train_data:\n",
    "            x.append(list(map(int, line.strip().split(' '))))\n",
    "    return x\n",
    "\n",
    "def read_labeled_data(labeled_index_data_path, threshold):\n",
    "    x = []\n",
    "    y = []\n",
    "    count_1 = 0\n",
    "    count_0 = 0\n",
    "    with open(labeled_index_data_path, 'r') as labeled_data:\n",
    "        for line in labeled_data:\n",
    "            label, text = line.strip().split(',')\n",
    "            if float(label) >= threshold:\n",
    "                label = 1\n",
    "                x.append(list(map(int, text.split(' '))))\n",
    "                y.append(int(label))\n",
    "                count_1 += 1\n",
    "            elif float(label) <= 1 - threshold:\n",
    "                label = 0\n",
    "                x.append(list(map(int, text.split(' '))))\n",
    "                y.append(int(label))\n",
    "                count_0 += 1\n",
    "    #print(count_1, count_0)\n",
    "    return x, y\n",
    "\n",
    "def generate_label(pred, x, labeled_index_data_path):\n",
    "    if os.path.isfile(labeled_index_data_path):\n",
    "        os.remove(labeled_index_data_path)\n",
    "    with open(labeled_index_data_path, 'a') as labeled_data:\n",
    "        for cntr in range(len(pred)):\n",
    "            s = ''\n",
    "            for ele in x[cntr]:\n",
    "                s += str(ele) +' '\n",
    "            labeled_data.write(str(pred[cntr][0]) +','+ s.strip() +'\\r\\n')\n",
    "            \n",
    "def read_dict(dict_path):\n",
    "    d = []\n",
    "    with open(dict_path, 'r') as dict_txt:\n",
    "        for line in dict_txt:\n",
    "            d.append(line.strip())\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 30\n",
    "val_cut = 10000\n",
    "x_train, y_train = read_train_data(training_label_index_data_path)\n",
    "#x_labeled, y_labeled = read_labeled_data(labeled_index_data_path, 0.95)\n",
    "#x_train = x_train\n",
    "#y_train = y_train\n",
    "#x_val, y_val = x_labeled[:val_cut], y_labeled[:val_cut]\n",
    "#x_test = read_test_data(testing_data_index_path)\n",
    "d = read_dict(dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_BOW_1(input_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='linear', input_shape=(input_size, )))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024, activation='linear'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vector = []\n",
    "for x in x_train:\n",
    "    x_vector = np.zeros(len(d) + 1)\n",
    "    for ele in x:\n",
    "        x_vector[ele] = 1\n",
    "    x_train_vector.append(x_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_BOW_1(len(d) + 1)\n",
    "#x_val_vector_batch = np.array(x_val_vector).reshape(np.array(x_val_vector).shape[0], len(d) + 1)\n",
    "epoch = 100\n",
    "batch_size = 128\n",
    "for e in range(epoch):\n",
    "    for i in range(int(len(x_train)/batch_size)):\n",
    "        if (i+1)*batch_size > 19999:\n",
    "            continue\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print('epoch:', (e+1), ' batch:', (i+1))\n",
    "        x_train_vector_batch = x_train_vector[i*batch_size:(i+1)*batch_size]\n",
    "        y_train_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "        x_train_vector_batch = np.array(x_train_vector_batch).reshape(np.array(x_train_vector_batch).shape[0], len(d) + 1)\n",
    "        model.train_on_batch(x_train_vector_batch, y_train_batch)\n",
    "model.save(model_path +'bow_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = read_test_data(testing_data_index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vector = []\n",
    "for x in x_test:\n",
    "    x_vector = np.zeros(len(d) + 1)\n",
    "    for ele in x:\n",
    "        x_vector[ele] = 1\n",
    "    x_test_vector.append(x_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "batch_size = 10000\n",
    "for i in range(20):  \n",
    "    print(i+1)\n",
    "    x_test_vector = []\n",
    "    for x in x_test[i*batch_size:(i+1)*batch_size]:\n",
    "        x_vector = np.zeros(len(d) + 1)\n",
    "        for ele in x:\n",
    "            x_vector[ele] = 1\n",
    "        x_test_vector.append(x_vector) \n",
    "    pred = model.predict(np.array(x_test_vector).reshape(np.array(x_test_vector).shape[0], len(d) + 1))\n",
    "    answer.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_write_answer(answer, answer_path):\n",
    "    if os.path.isfile(answer_path):\n",
    "        os.remove(answer_path)\n",
    "    with open(answer_path, 'a') as bow_answer:\n",
    "        index = 0\n",
    "        bow_answer.write('id,label\\r\\n')\n",
    "        for pred in answer:\n",
    "            for score in pred:\n",
    "                if score >= 0.5:\n",
    "                    bow_answer.write(str(index) +',1\\r\\n')\n",
    "                else:\n",
    "                    bow_answer.write(str(index) +',0\\r\\n')\n",
    "                index += 1\n",
    "            \n",
    "bow_write_answer(answer, bow_answer_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
