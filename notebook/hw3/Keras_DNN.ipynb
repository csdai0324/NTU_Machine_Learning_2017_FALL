{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Add, Input, Multiply, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './train.csv'\n",
    "test_data_path ='./test.csv'\n",
    "val_data_path ='./val.csv'\n",
    "answer_path ='./prediction.csv'\n",
    "batch_size = 64\n",
    "num_classes = 7\n",
    "epochs = 50\n",
    "img_rows, img_cols = 48, 48\n",
    "input_shape = (img_rows*img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(train_data_path):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(train_data_path, 'r') as train_data:\n",
    "        train_data.readline()\n",
    "        for line in train_data:\n",
    "            label, pixels = line.strip().split(',')\n",
    "            pixels = list(map(int, pixels.split(' ')))\n",
    "            x.append(pixels)\n",
    "            y.append(int(label))\n",
    "    return x, y\n",
    "\n",
    "def read_test_data(test_data_path):\n",
    "    x = []\n",
    "    with open(test_data_path, 'r') as test_data:\n",
    "        test_data.readline()\n",
    "        for line in test_data:\n",
    "            label, pixels = line.strip().split(',')\n",
    "            pixels = list(map(int, pixels.split(' ')))\n",
    "            x.append(pixels)\n",
    "    return x\n",
    "\n",
    "def read_val_data(val_data_path):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(val_data_path, 'r') as val_data:\n",
    "        val_data.readline()\n",
    "        for line in val_data:\n",
    "            label, pixels, tag = line.strip().split(',')\n",
    "            if tag =='PrivateTest' or tag =='PublicTest':\n",
    "                pixels = list(map(int, pixels.split(' ')))\n",
    "                x.append(pixels)\n",
    "                y.append(int(label))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_train_data(train_data_path)\n",
    "x_val, y_val = read_val_data(val_data_path)\n",
    "x_train = np.array(x_train).reshape(np.array(x_train).shape[0], img_rows*img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "x_val = np.array(x_val).reshape(np.array(x_val).shape[0], img_rows*img_cols)\n",
    "x_val = x_val.astype('float32')\n",
    "x_val /= 255\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='linear', input_shape=(img_rows*img_cols, )))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7178 samples\n",
      "Epoch 1/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 1.7112 - acc: 0.3428 - val_loss: 1.7448 - val_acc: 0.3018\n",
      "Epoch 2/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 1.6596 - acc: 0.3557 - val_loss: 1.6117 - val_acc: 0.3738\n",
      "Epoch 3/250\n",
      "28709/28709 [==============================] - 3s 95us/step - loss: 1.6011 - acc: 0.3763 - val_loss: 1.9057 - val_acc: 0.2799\n",
      "Epoch 4/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 1.5730 - acc: 0.3882 - val_loss: 1.6975 - val_acc: 0.3466\n",
      "Epoch 5/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 1.5397 - acc: 0.4029 - val_loss: 1.7160 - val_acc: 0.2981\n",
      "Epoch 6/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 1.5076 - acc: 0.4144 - val_loss: 1.6174 - val_acc: 0.3665\n",
      "Epoch 7/250\n",
      "28709/28709 [==============================] - 3s 92us/step - loss: 1.4870 - acc: 0.4216 - val_loss: 1.8452 - val_acc: 0.2242\n",
      "Epoch 8/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.4650 - acc: 0.4338 - val_loss: 1.7651 - val_acc: 0.3615\n",
      "Epoch 9/250\n",
      "28709/28709 [==============================] - 3s 93us/step - loss: 1.4508 - acc: 0.4390 - val_loss: 1.7940 - val_acc: 0.3370\n",
      "Epoch 10/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 1.4274 - acc: 0.4483 - val_loss: 1.6405 - val_acc: 0.3600\n",
      "Epoch 11/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 1.4152 - acc: 0.4509 - val_loss: 1.8779 - val_acc: 0.3254\n",
      "Epoch 12/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 1.3957 - acc: 0.4612 - val_loss: 1.6618 - val_acc: 0.3480\n",
      "Epoch 13/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 1.3775 - acc: 0.4683 - val_loss: 1.6081 - val_acc: 0.3865\n",
      "Epoch 14/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 1.3588 - acc: 0.4787 - val_loss: 1.6770 - val_acc: 0.3169\n",
      "Epoch 15/250\n",
      "28709/28709 [==============================] - 2s 85us/step - loss: 1.3409 - acc: 0.4818 - val_loss: 1.6125 - val_acc: 0.4193\n",
      "Epoch 16/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 1.3241 - acc: 0.4901 - val_loss: 1.7498 - val_acc: 0.3572\n",
      "Epoch 17/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.3108 - acc: 0.4960 - val_loss: 1.6358 - val_acc: 0.3611\n",
      "Epoch 18/250\n",
      "28709/28709 [==============================] - 3s 92us/step - loss: 1.2904 - acc: 0.5075 - val_loss: 1.6346 - val_acc: 0.3660\n",
      "Epoch 19/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 1.2766 - acc: 0.5142 - val_loss: 1.7090 - val_acc: 0.3547\n",
      "Epoch 20/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.2543 - acc: 0.5218 - val_loss: 1.6732 - val_acc: 0.3911\n",
      "Epoch 21/250\n",
      "28709/28709 [==============================] - 3s 93us/step - loss: 1.2460 - acc: 0.5247 - val_loss: 1.7124 - val_acc: 0.3369\n",
      "Epoch 22/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 1.2196 - acc: 0.5349 - val_loss: 1.7833 - val_acc: 0.3066\n",
      "Epoch 23/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 1.2123 - acc: 0.5372 - val_loss: 1.6645 - val_acc: 0.3859\n",
      "Epoch 24/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 1.1926 - acc: 0.5432 - val_loss: 1.6037 - val_acc: 0.3922\n",
      "Epoch 25/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 1.1814 - acc: 0.5506 - val_loss: 1.6878 - val_acc: 0.3275\n",
      "Epoch 26/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 1.1577 - acc: 0.5602 - val_loss: 2.0124 - val_acc: 0.3328\n",
      "Epoch 27/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 1.1432 - acc: 0.5663 - val_loss: 1.6148 - val_acc: 0.3957\n",
      "Epoch 28/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 1.1302 - acc: 0.5706 - val_loss: 1.9957 - val_acc: 0.2940\n",
      "Epoch 29/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.1157 - acc: 0.5771 - val_loss: 1.7180 - val_acc: 0.3784\n",
      "Epoch 30/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.1020 - acc: 0.5811 - val_loss: 1.6461 - val_acc: 0.3930\n",
      "Epoch 31/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 1.0908 - acc: 0.5875 - val_loss: 2.2415 - val_acc: 0.2612\n",
      "Epoch 32/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.0595 - acc: 0.6018 - val_loss: 1.8753 - val_acc: 0.3427\n",
      "Epoch 33/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 1.0496 - acc: 0.6062 - val_loss: 1.8536 - val_acc: 0.3668\n",
      "Epoch 34/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.0395 - acc: 0.6105 - val_loss: 1.6901 - val_acc: 0.3852\n",
      "Epoch 35/250\n",
      "28709/28709 [==============================] - 2s 83us/step - loss: 1.0222 - acc: 0.6155 - val_loss: 1.7066 - val_acc: 0.3763\n",
      "Epoch 36/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 1.0009 - acc: 0.6238 - val_loss: 2.2113 - val_acc: 0.3717\n",
      "Epoch 37/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.9973 - acc: 0.6257 - val_loss: 1.8258 - val_acc: 0.4016\n",
      "Epoch 38/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.9863 - acc: 0.6298 - val_loss: 1.6705 - val_acc: 0.3899\n",
      "Epoch 39/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.9583 - acc: 0.6403 - val_loss: 1.6463 - val_acc: 0.4196\n",
      "Epoch 40/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.9427 - acc: 0.6480 - val_loss: 1.9140 - val_acc: 0.3725\n",
      "Epoch 41/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.9439 - acc: 0.6472 - val_loss: 1.8172 - val_acc: 0.3840\n",
      "Epoch 42/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.9238 - acc: 0.6555 - val_loss: 2.3044 - val_acc: 0.3115\n",
      "Epoch 43/250\n",
      "28709/28709 [==============================] - 3s 92us/step - loss: 0.9073 - acc: 0.6635 - val_loss: 2.1333 - val_acc: 0.2827\n",
      "Epoch 44/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.8930 - acc: 0.6688 - val_loss: 2.1205 - val_acc: 0.3479\n",
      "Epoch 45/250\n",
      "28709/28709 [==============================] - 2s 83us/step - loss: 0.8828 - acc: 0.6694 - val_loss: 2.1639 - val_acc: 0.3420\n",
      "Epoch 46/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.8727 - acc: 0.6757 - val_loss: 2.2616 - val_acc: 0.3796\n",
      "Epoch 47/250\n",
      "28709/28709 [==============================] - 3s 92us/step - loss: 0.8540 - acc: 0.6829 - val_loss: 2.7272 - val_acc: 0.2537\n",
      "Epoch 48/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.8480 - acc: 0.6845 - val_loss: 2.2324 - val_acc: 0.3208\n",
      "Epoch 49/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.8334 - acc: 0.6894 - val_loss: 1.9975 - val_acc: 0.4036\n",
      "Epoch 50/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.8249 - acc: 0.6924 - val_loss: 2.0036 - val_acc: 0.3447\n",
      "Epoch 51/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.8129 - acc: 0.6996 - val_loss: 2.1353 - val_acc: 0.3796\n",
      "Epoch 52/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.7998 - acc: 0.7020 - val_loss: 2.3141 - val_acc: 0.3430\n",
      "Epoch 53/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.7830 - acc: 0.7081 - val_loss: 2.1323 - val_acc: 0.4047\n",
      "Epoch 54/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.7743 - acc: 0.7089 - val_loss: 2.2509 - val_acc: 0.3603\n",
      "Epoch 55/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.7647 - acc: 0.7177 - val_loss: 2.7545 - val_acc: 0.3048\n",
      "Epoch 56/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.7470 - acc: 0.7228 - val_loss: 2.4139 - val_acc: 0.3798\n",
      "Epoch 57/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.7405 - acc: 0.7254 - val_loss: 2.1160 - val_acc: 0.3833\n",
      "Epoch 58/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.7298 - acc: 0.7292 - val_loss: 2.1461 - val_acc: 0.4241\n",
      "Epoch 59/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.7261 - acc: 0.7307 - val_loss: 2.1761 - val_acc: 0.4182\n",
      "Epoch 60/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.7215 - acc: 0.7348 - val_loss: 2.0714 - val_acc: 0.3841\n",
      "Epoch 61/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.7104 - acc: 0.7353 - val_loss: 2.7466 - val_acc: 0.3494\n",
      "Epoch 62/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.6893 - acc: 0.7470 - val_loss: 2.7706 - val_acc: 0.3468\n",
      "Epoch 63/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.6945 - acc: 0.7476 - val_loss: 2.5984 - val_acc: 0.3194\n",
      "Epoch 64/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.6808 - acc: 0.7497 - val_loss: 2.4486 - val_acc: 0.4153\n",
      "Epoch 65/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.6538 - acc: 0.7577 - val_loss: 2.2860 - val_acc: 0.3842\n",
      "Epoch 66/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.6673 - acc: 0.7528 - val_loss: 2.1340 - val_acc: 0.3681\n",
      "Epoch 67/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.6493 - acc: 0.7614 - val_loss: 2.0246 - val_acc: 0.4022\n",
      "Epoch 68/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.6364 - acc: 0.7644 - val_loss: 2.4375 - val_acc: 0.3192\n",
      "Epoch 69/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.6367 - acc: 0.7656 - val_loss: 3.0745 - val_acc: 0.3756\n",
      "Epoch 70/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.6227 - acc: 0.7717 - val_loss: 2.4175 - val_acc: 0.3997\n",
      "Epoch 71/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.6167 - acc: 0.7733 - val_loss: 2.2704 - val_acc: 0.3989\n",
      "Epoch 72/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.6087 - acc: 0.7756 - val_loss: 2.2276 - val_acc: 0.3688\n",
      "Epoch 73/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.5972 - acc: 0.7815 - val_loss: 2.9806 - val_acc: 0.3069\n",
      "Epoch 74/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.5994 - acc: 0.7829 - val_loss: 2.1358 - val_acc: 0.4170\n",
      "Epoch 75/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.5880 - acc: 0.7844 - val_loss: 2.4503 - val_acc: 0.3778\n",
      "Epoch 76/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.5828 - acc: 0.7883 - val_loss: 2.1562 - val_acc: 0.4097\n",
      "Epoch 77/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.5795 - acc: 0.7893 - val_loss: 2.2530 - val_acc: 0.3540\n",
      "Epoch 78/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.5707 - acc: 0.7920 - val_loss: 2.3474 - val_acc: 0.3931\n",
      "Epoch 79/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.5642 - acc: 0.7950 - val_loss: 2.4341 - val_acc: 0.3965\n",
      "Epoch 80/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.5552 - acc: 0.7985 - val_loss: 2.5283 - val_acc: 0.3824\n",
      "Epoch 81/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.5500 - acc: 0.7978 - val_loss: 2.6269 - val_acc: 0.3760\n",
      "Epoch 82/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.5433 - acc: 0.8003 - val_loss: 2.4534 - val_acc: 0.4037\n",
      "Epoch 83/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.5283 - acc: 0.8065 - val_loss: 2.9558 - val_acc: 0.3402\n",
      "Epoch 84/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.5327 - acc: 0.8071 - val_loss: 2.2907 - val_acc: 0.3672\n",
      "Epoch 85/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.5327 - acc: 0.8064 - val_loss: 2.2895 - val_acc: 0.4068\n",
      "Epoch 86/250\n",
      "28709/28709 [==============================] - 2s 83us/step - loss: 0.5167 - acc: 0.8120 - val_loss: 3.1544 - val_acc: 0.4078\n",
      "Epoch 87/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.5048 - acc: 0.8161 - val_loss: 2.8673 - val_acc: 0.3930\n",
      "Epoch 88/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.5038 - acc: 0.8185 - val_loss: 3.0547 - val_acc: 0.3767\n",
      "Epoch 89/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.4981 - acc: 0.8173 - val_loss: 2.2996 - val_acc: 0.4142\n",
      "Epoch 90/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.5027 - acc: 0.8187 - val_loss: 2.4850 - val_acc: 0.3898\n",
      "Epoch 91/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.4840 - acc: 0.8230 - val_loss: 2.4568 - val_acc: 0.4118\n",
      "Epoch 92/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.4897 - acc: 0.8212 - val_loss: 2.8265 - val_acc: 0.3612\n",
      "Epoch 93/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.4788 - acc: 0.8261 - val_loss: 2.5473 - val_acc: 0.4094\n",
      "Epoch 94/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.4777 - acc: 0.8287 - val_loss: 2.9310 - val_acc: 0.3431\n",
      "Epoch 95/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.4715 - acc: 0.8299 - val_loss: 2.8117 - val_acc: 0.3775\n",
      "Epoch 96/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.4570 - acc: 0.8339 - val_loss: 2.4922 - val_acc: 0.4086\n",
      "Epoch 97/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.4658 - acc: 0.8305 - val_loss: 3.0532 - val_acc: 0.3461\n",
      "Epoch 98/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.4606 - acc: 0.8299 - val_loss: 2.5581 - val_acc: 0.3908\n",
      "Epoch 99/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.4491 - acc: 0.8368 - val_loss: 2.4878 - val_acc: 0.3905\n",
      "Epoch 100/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.4431 - acc: 0.8401 - val_loss: 3.0273 - val_acc: 0.3638\n",
      "Epoch 101/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.4433 - acc: 0.8413 - val_loss: 2.5760 - val_acc: 0.4140\n",
      "Epoch 102/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.4449 - acc: 0.8377 - val_loss: 2.6596 - val_acc: 0.3819\n",
      "Epoch 103/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.4301 - acc: 0.8478 - val_loss: 2.7385 - val_acc: 0.3764\n",
      "Epoch 104/250\n",
      "28709/28709 [==============================] - 3s 92us/step - loss: 0.4243 - acc: 0.8473 - val_loss: 2.5442 - val_acc: 0.3651\n",
      "Epoch 105/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.4182 - acc: 0.8465 - val_loss: 2.7410 - val_acc: 0.3970\n",
      "Epoch 106/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.4216 - acc: 0.8473 - val_loss: 2.5051 - val_acc: 0.4033\n",
      "Epoch 107/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.4132 - acc: 0.8506 - val_loss: 3.4199 - val_acc: 0.3604\n",
      "Epoch 108/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.4057 - acc: 0.8529 - val_loss: 2.7717 - val_acc: 0.4147\n",
      "Epoch 109/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.4113 - acc: 0.8536 - val_loss: 3.0563 - val_acc: 0.3554\n",
      "Epoch 110/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.4035 - acc: 0.8535 - val_loss: 2.6478 - val_acc: 0.3894\n",
      "Epoch 111/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.4027 - acc: 0.8556 - val_loss: 2.4991 - val_acc: 0.4046\n",
      "Epoch 112/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.4052 - acc: 0.8556 - val_loss: 3.3706 - val_acc: 0.3303\n",
      "Epoch 113/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.3882 - acc: 0.8585 - val_loss: 3.4174 - val_acc: 0.3452\n",
      "Epoch 114/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.3879 - acc: 0.8599 - val_loss: 3.0527 - val_acc: 0.3561\n",
      "Epoch 115/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.3819 - acc: 0.8630 - val_loss: 2.6954 - val_acc: 0.3936\n",
      "Epoch 116/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3861 - acc: 0.8606 - val_loss: 2.7352 - val_acc: 0.4245\n",
      "Epoch 117/250\n",
      "28709/28709 [==============================] - 3s 93us/step - loss: 0.3849 - acc: 0.8629 - val_loss: 3.0262 - val_acc: 0.3810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.3769 - acc: 0.8663 - val_loss: 3.5407 - val_acc: 0.4166\n",
      "Epoch 119/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.3812 - acc: 0.8623 - val_loss: 3.5503 - val_acc: 0.3261\n",
      "Epoch 120/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3690 - acc: 0.8669 - val_loss: 2.7337 - val_acc: 0.3912\n",
      "Epoch 121/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.3720 - acc: 0.8647 - val_loss: 2.6166 - val_acc: 0.3741\n",
      "Epoch 122/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.3628 - acc: 0.8706 - val_loss: 3.2090 - val_acc: 0.3461\n",
      "Epoch 123/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.3699 - acc: 0.8675 - val_loss: 3.1053 - val_acc: 0.4114\n",
      "Epoch 124/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.3628 - acc: 0.8687 - val_loss: 2.6722 - val_acc: 0.4103\n",
      "Epoch 125/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.3572 - acc: 0.8724 - val_loss: 2.6981 - val_acc: 0.4207\n",
      "Epoch 126/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.3575 - acc: 0.8723 - val_loss: 3.1814 - val_acc: 0.3447\n",
      "Epoch 127/250\n",
      "28709/28709 [==============================] - 3s 93us/step - loss: 0.3520 - acc: 0.8739 - val_loss: 3.3584 - val_acc: 0.3656\n",
      "Epoch 128/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.3574 - acc: 0.8728 - val_loss: 3.0991 - val_acc: 0.3746\n",
      "Epoch 129/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.3464 - acc: 0.8768 - val_loss: 3.1419 - val_acc: 0.3610\n",
      "Epoch 130/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.3459 - acc: 0.8763 - val_loss: 3.0383 - val_acc: 0.3704\n",
      "Epoch 131/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.3367 - acc: 0.8802 - val_loss: 3.6036 - val_acc: 0.3930\n",
      "Epoch 132/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.3412 - acc: 0.8783 - val_loss: 3.9438 - val_acc: 0.3289\n",
      "Epoch 133/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.3330 - acc: 0.8802 - val_loss: 2.9206 - val_acc: 0.3998\n",
      "Epoch 134/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3377 - acc: 0.8801 - val_loss: 3.1416 - val_acc: 0.4210\n",
      "Epoch 135/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3424 - acc: 0.8782 - val_loss: 2.7642 - val_acc: 0.4061\n",
      "Epoch 136/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.3272 - acc: 0.8840 - val_loss: 2.5812 - val_acc: 0.3972\n",
      "Epoch 137/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3262 - acc: 0.8837 - val_loss: 3.1754 - val_acc: 0.3486\n",
      "Epoch 138/250\n",
      "28709/28709 [==============================] - 3s 93us/step - loss: 0.3260 - acc: 0.8838 - val_loss: 3.6794 - val_acc: 0.3710\n",
      "Epoch 139/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.3154 - acc: 0.8894 - val_loss: 3.3793 - val_acc: 0.3631\n",
      "Epoch 140/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.3268 - acc: 0.8851 - val_loss: 2.8167 - val_acc: 0.4094\n",
      "Epoch 141/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3246 - acc: 0.8847 - val_loss: 2.7758 - val_acc: 0.4007\n",
      "Epoch 142/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.3219 - acc: 0.8844 - val_loss: 2.7022 - val_acc: 0.4126\n",
      "Epoch 143/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.3174 - acc: 0.8875 - val_loss: 2.9398 - val_acc: 0.4281\n",
      "Epoch 144/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.3054 - acc: 0.8922 - val_loss: 2.7127 - val_acc: 0.4179\n",
      "Epoch 145/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.3103 - acc: 0.8906 - val_loss: 3.5349 - val_acc: 0.3394\n",
      "Epoch 146/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3075 - acc: 0.8899 - val_loss: 2.8601 - val_acc: 0.3891\n",
      "Epoch 147/250\n",
      "28709/28709 [==============================] - 2s 85us/step - loss: 0.2937 - acc: 0.8965 - val_loss: 3.2758 - val_acc: 0.3828\n",
      "Epoch 148/250\n",
      "28709/28709 [==============================] - 3s 92us/step - loss: 0.3026 - acc: 0.8930 - val_loss: 3.4185 - val_acc: 0.3869\n",
      "Epoch 149/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.3047 - acc: 0.8909 - val_loss: 4.3812 - val_acc: 0.2863\n",
      "Epoch 150/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.3062 - acc: 0.8904 - val_loss: 3.8689 - val_acc: 0.2992\n",
      "Epoch 151/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.3049 - acc: 0.8923 - val_loss: 3.3907 - val_acc: 0.3969\n",
      "Epoch 152/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2978 - acc: 0.8938 - val_loss: 3.3976 - val_acc: 0.3438\n",
      "Epoch 153/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2923 - acc: 0.8977 - val_loss: 3.0082 - val_acc: 0.4188\n",
      "Epoch 154/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2932 - acc: 0.8946 - val_loss: 3.6393 - val_acc: 0.3337\n",
      "Epoch 155/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2839 - acc: 0.8982 - val_loss: 3.5900 - val_acc: 0.4094\n",
      "Epoch 156/250\n",
      "28709/28709 [==============================] - 2s 85us/step - loss: 0.2925 - acc: 0.8984 - val_loss: 3.0627 - val_acc: 0.4164\n",
      "Epoch 157/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2951 - acc: 0.8956 - val_loss: 3.3349 - val_acc: 0.3419\n",
      "Epoch 158/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2882 - acc: 0.8967 - val_loss: 3.1320 - val_acc: 0.4154\n",
      "Epoch 159/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2776 - acc: 0.9014 - val_loss: 3.6656 - val_acc: 0.3483\n",
      "Epoch 160/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2885 - acc: 0.8970 - val_loss: 2.9162 - val_acc: 0.4115\n",
      "Epoch 161/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2799 - acc: 0.8995 - val_loss: 3.4185 - val_acc: 0.3639\n",
      "Epoch 162/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2813 - acc: 0.8997 - val_loss: 3.7801 - val_acc: 0.3759\n",
      "Epoch 163/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2810 - acc: 0.9019 - val_loss: 3.1357 - val_acc: 0.4179\n",
      "Epoch 164/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2867 - acc: 0.8977 - val_loss: 3.2600 - val_acc: 0.3983\n",
      "Epoch 165/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2748 - acc: 0.9025 - val_loss: 3.0581 - val_acc: 0.3826\n",
      "Epoch 166/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2677 - acc: 0.9062 - val_loss: 3.8212 - val_acc: 0.3363\n",
      "Epoch 167/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2802 - acc: 0.9029 - val_loss: 3.2825 - val_acc: 0.4079\n",
      "Epoch 168/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2736 - acc: 0.9041 - val_loss: 3.3112 - val_acc: 0.3948\n",
      "Epoch 169/250\n",
      "28709/28709 [==============================] - 3s 92us/step - loss: 0.2752 - acc: 0.9037 - val_loss: 3.3218 - val_acc: 0.4060\n",
      "Epoch 170/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2702 - acc: 0.9045 - val_loss: 3.9015 - val_acc: 0.3739\n",
      "Epoch 171/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2644 - acc: 0.9073 - val_loss: 3.4476 - val_acc: 0.4040\n",
      "Epoch 172/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2609 - acc: 0.9087 - val_loss: 4.1238 - val_acc: 0.3468\n",
      "Epoch 173/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2706 - acc: 0.9037 - val_loss: 3.1569 - val_acc: 0.4099\n",
      "Epoch 174/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2635 - acc: 0.9082 - val_loss: 3.2376 - val_acc: 0.4040\n",
      "Epoch 175/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2548 - acc: 0.9092 - val_loss: 3.0473 - val_acc: 0.4331\n",
      "Epoch 176/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.2650 - acc: 0.9064 - val_loss: 3.1294 - val_acc: 0.4167\n",
      "Epoch 177/250\n",
      "28709/28709 [==============================] - 2s 84us/step - loss: 0.2566 - acc: 0.9093 - val_loss: 3.2109 - val_acc: 0.3911\n",
      "Epoch 178/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2601 - acc: 0.9091 - val_loss: 2.9468 - val_acc: 0.4248\n",
      "Epoch 179/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2527 - acc: 0.9103 - val_loss: 3.5326 - val_acc: 0.3856\n",
      "Epoch 180/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2512 - acc: 0.9131 - val_loss: 3.0013 - val_acc: 0.4209\n",
      "Epoch 181/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2571 - acc: 0.9108 - val_loss: 3.5571 - val_acc: 0.4234\n",
      "Epoch 182/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2515 - acc: 0.9095 - val_loss: 3.5265 - val_acc: 0.3989\n",
      "Epoch 183/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2494 - acc: 0.9110 - val_loss: 3.1703 - val_acc: 0.4257\n",
      "Epoch 184/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2459 - acc: 0.9135 - val_loss: 3.0543 - val_acc: 0.4142\n",
      "Epoch 185/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2426 - acc: 0.9169 - val_loss: 3.6620 - val_acc: 0.3834\n",
      "Epoch 186/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2368 - acc: 0.9183 - val_loss: 3.8439 - val_acc: 0.3146\n",
      "Epoch 187/250\n",
      "28709/28709 [==============================] - 2s 82us/step - loss: 0.2512 - acc: 0.9107 - val_loss: 3.0180 - val_acc: 0.4100\n",
      "Epoch 188/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2506 - acc: 0.9106 - val_loss: 3.2819 - val_acc: 0.4200\n",
      "Epoch 189/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2351 - acc: 0.9163 - val_loss: 3.3054 - val_acc: 0.3760\n",
      "Epoch 190/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.2389 - acc: 0.9165 - val_loss: 3.5000 - val_acc: 0.3671\n",
      "Epoch 191/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2382 - acc: 0.9175 - val_loss: 3.0067 - val_acc: 0.4048\n",
      "Epoch 192/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2400 - acc: 0.9160 - val_loss: 3.4183 - val_acc: 0.3835\n",
      "Epoch 193/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2431 - acc: 0.9127 - val_loss: 3.4785 - val_acc: 0.3887\n",
      "Epoch 194/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2355 - acc: 0.9155 - val_loss: 3.2855 - val_acc: 0.3674\n",
      "Epoch 195/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2454 - acc: 0.9131 - val_loss: 3.5090 - val_acc: 0.3872\n",
      "Epoch 196/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.2339 - acc: 0.9178 - val_loss: 3.3924 - val_acc: 0.4327\n",
      "Epoch 197/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2308 - acc: 0.9173 - val_loss: 3.2324 - val_acc: 0.4147\n",
      "Epoch 198/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.2400 - acc: 0.9147 - val_loss: 3.1804 - val_acc: 0.4485\n",
      "Epoch 199/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.2390 - acc: 0.9149 - val_loss: 3.3790 - val_acc: 0.3788\n",
      "Epoch 200/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2272 - acc: 0.9191 - val_loss: 3.8661 - val_acc: 0.4029\n",
      "Epoch 201/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2294 - acc: 0.9205 - val_loss: 3.4236 - val_acc: 0.4213\n",
      "Epoch 202/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2265 - acc: 0.9203 - val_loss: 4.2596 - val_acc: 0.3369\n",
      "Epoch 203/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2281 - acc: 0.9190 - val_loss: 3.9910 - val_acc: 0.3697\n",
      "Epoch 204/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2324 - acc: 0.9195 - val_loss: 3.2175 - val_acc: 0.4298\n",
      "Epoch 205/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2198 - acc: 0.9233 - val_loss: 3.2041 - val_acc: 0.4235\n",
      "Epoch 206/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2127 - acc: 0.9249 - val_loss: 3.0668 - val_acc: 0.4238\n",
      "Epoch 207/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2242 - acc: 0.9219 - val_loss: 3.2099 - val_acc: 0.4136\n",
      "Epoch 208/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2262 - acc: 0.9213 - val_loss: 3.1691 - val_acc: 0.4135\n",
      "Epoch 209/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2225 - acc: 0.9210 - val_loss: 3.4069 - val_acc: 0.3819\n",
      "Epoch 210/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2207 - acc: 0.9217 - val_loss: 3.7974 - val_acc: 0.4075\n",
      "Epoch 211/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2172 - acc: 0.9240 - val_loss: 3.6434 - val_acc: 0.3936\n",
      "Epoch 212/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2205 - acc: 0.9226 - val_loss: 2.9444 - val_acc: 0.4274\n",
      "Epoch 213/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2095 - acc: 0.9265 - val_loss: 3.9341 - val_acc: 0.3842\n",
      "Epoch 214/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.2190 - acc: 0.9221 - val_loss: 3.9831 - val_acc: 0.4012\n",
      "Epoch 215/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2199 - acc: 0.9219 - val_loss: 3.1116 - val_acc: 0.4235\n",
      "Epoch 216/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2188 - acc: 0.9249 - val_loss: 3.1233 - val_acc: 0.4164\n",
      "Epoch 217/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2282 - acc: 0.9201 - val_loss: 3.4969 - val_acc: 0.3764\n",
      "Epoch 218/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2093 - acc: 0.9249 - val_loss: 3.8396 - val_acc: 0.3586\n",
      "Epoch 219/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2110 - acc: 0.9264 - val_loss: 3.4266 - val_acc: 0.4050\n",
      "Epoch 220/250\n",
      "28709/28709 [==============================] - 2s 87us/step - loss: 0.2102 - acc: 0.9270 - val_loss: 5.0282 - val_acc: 0.3065\n",
      "Epoch 221/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2092 - acc: 0.9271 - val_loss: 2.9940 - val_acc: 0.4327\n",
      "Epoch 222/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2114 - acc: 0.9258 - val_loss: 3.3713 - val_acc: 0.4035\n",
      "Epoch 223/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2079 - acc: 0.9273 - val_loss: 4.2464 - val_acc: 0.3381\n",
      "Epoch 224/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2028 - acc: 0.9288 - val_loss: 3.3181 - val_acc: 0.4195\n",
      "Epoch 225/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2097 - acc: 0.9261 - val_loss: 3.3466 - val_acc: 0.4014\n",
      "Epoch 226/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2043 - acc: 0.9286 - val_loss: 3.2555 - val_acc: 0.4142\n",
      "Epoch 227/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2058 - acc: 0.9287 - val_loss: 3.5716 - val_acc: 0.3826\n",
      "Epoch 228/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.2145 - acc: 0.9253 - val_loss: 3.5468 - val_acc: 0.3902\n",
      "Epoch 229/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2101 - acc: 0.9266 - val_loss: 3.1348 - val_acc: 0.3993\n",
      "Epoch 230/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.1909 - acc: 0.9320 - val_loss: 3.5055 - val_acc: 0.3941\n",
      "Epoch 231/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.2036 - acc: 0.9287 - val_loss: 3.4933 - val_acc: 0.4166\n",
      "Epoch 232/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2086 - acc: 0.9288 - val_loss: 3.1799 - val_acc: 0.4145\n",
      "Epoch 233/250\n",
      "28709/28709 [==============================] - 3s 87us/step - loss: 0.2035 - acc: 0.9301 - val_loss: 3.6099 - val_acc: 0.4029\n",
      "Epoch 234/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.1953 - acc: 0.9313 - val_loss: 3.5578 - val_acc: 0.3895\n",
      "Epoch 235/250\n",
      "28709/28709 [==============================] - 2s 84us/step - loss: 0.2054 - acc: 0.9293 - val_loss: 3.5888 - val_acc: 0.3929\n",
      "Epoch 236/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.1961 - acc: 0.9302 - val_loss: 3.2165 - val_acc: 0.4126\n",
      "Epoch 237/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.1937 - acc: 0.9308 - val_loss: 3.2110 - val_acc: 0.4205\n",
      "Epoch 238/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.1992 - acc: 0.9321 - val_loss: 3.1865 - val_acc: 0.4207\n",
      "Epoch 239/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.1932 - acc: 0.9340 - val_loss: 3.4695 - val_acc: 0.4209\n",
      "Epoch 240/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.2059 - acc: 0.9288 - val_loss: 3.4911 - val_acc: 0.4154\n",
      "Epoch 241/250\n",
      "28709/28709 [==============================] - 3s 89us/step - loss: 0.2049 - acc: 0.9294 - val_loss: 3.5074 - val_acc: 0.3918\n",
      "Epoch 242/250\n",
      "28709/28709 [==============================] - 2s 85us/step - loss: 0.1920 - acc: 0.9294 - val_loss: 4.1058 - val_acc: 0.3583\n",
      "Epoch 243/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.1948 - acc: 0.9320 - val_loss: 3.3116 - val_acc: 0.4120\n",
      "Epoch 244/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.1922 - acc: 0.9324 - val_loss: 3.1542 - val_acc: 0.4133\n",
      "Epoch 245/250\n",
      "28709/28709 [==============================] - 3s 91us/step - loss: 0.2064 - acc: 0.9281 - val_loss: 3.6517 - val_acc: 0.3936\n",
      "Epoch 246/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.1897 - acc: 0.9341 - val_loss: 3.6921 - val_acc: 0.4015\n",
      "Epoch 247/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.1943 - acc: 0.9327 - val_loss: 3.5547 - val_acc: 0.4218\n",
      "Epoch 248/250\n",
      "28709/28709 [==============================] - 2s 86us/step - loss: 0.1943 - acc: 0.9326 - val_loss: 3.7441 - val_acc: 0.3884\n",
      "Epoch 249/250\n",
      "28709/28709 [==============================] - 3s 90us/step - loss: 0.1937 - acc: 0.9320 - val_loss: 3.5927 - val_acc: 0.3951\n",
      "Epoch 250/250\n",
      "28709/28709 [==============================] - 3s 88us/step - loss: 0.1813 - acc: 0.9374 - val_loss: 3.8879 - val_acc: 0.3395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=128,\n",
    "                    verbose=1, epochs=250, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 5,532,679\n",
      "Trainable params: 5,524,487\n",
      "Non-trainable params: 8,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
