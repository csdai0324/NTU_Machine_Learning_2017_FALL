{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Add, Input, Multiply, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './train.csv'\n",
    "test_data_path ='./test.csv'\n",
    "val_data_path ='./val.csv'\n",
    "answer_path ='./prediction.csv'\n",
    "batch_size = 64\n",
    "num_classes = 7\n",
    "epochs = 50\n",
    "img_rows, img_cols = 48, 48\n",
    "input_shape = (48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(train_data_path):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(train_data_path, 'r') as train_data:\n",
    "        train_data.readline()\n",
    "        for line in train_data:\n",
    "            label, pixels = line.strip().split(',')\n",
    "            pixels = list(map(int, pixels.split(' ')))\n",
    "            x.append(pixels)\n",
    "            y.append(int(label))\n",
    "    return x, y\n",
    "\n",
    "def read_test_data(test_data_path):\n",
    "    x = []\n",
    "    with open(test_data_path, 'r') as test_data:\n",
    "        test_data.readline()\n",
    "        for line in test_data:\n",
    "            label, pixels = line.strip().split(',')\n",
    "            pixels = list(map(int, pixels.split(' ')))\n",
    "            x.append(pixels)\n",
    "    return x\n",
    "\n",
    "def read_val_data(val_data_path):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(val_data_path, 'r') as val_data:\n",
    "        val_data.readline()\n",
    "        for line in val_data:\n",
    "            label, pixels, tag = line.strip().split(',')\n",
    "            if tag =='PrivateTest' or tag =='PublicTest':\n",
    "                pixels = list(map(int, pixels.split(' ')))\n",
    "                x.append(pixels)\n",
    "                y.append(int(label))\n",
    "    return x, y\n",
    "\n",
    "def write_answer(answer_path, pred):\n",
    "    if os.path.exists(answer_path):\n",
    "        os.remove(answer_path)\n",
    "    with open(answer_path, 'a') as ans:\n",
    "        ans.write('id,label\\r\\n')\n",
    "        id = 0\n",
    "        for vec in pred:\n",
    "            str = '%d,%d\\r\\n'% (id, list(vec).index(max(vec)))\n",
    "            id += 1\n",
    "            ans.write(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_train_data(train_data_path)\n",
    "x_val, y_val = read_val_data(val_data_path)\n",
    "\n",
    "x_train = np.array(x_train).reshape(np.array(x_train).shape[0], img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "x_val = np.array(x_val).reshape(np.array(x_val).shape[0], img_rows, img_cols, 1)\n",
    "x_val = x_val.astype('float32')\n",
    "x_val /= 255\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', input_shape=input_shape, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Conv2D(32, (3, 3), activation='linear', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='same', data_format=None))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='linear', input_shape=input_shape, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Conv2D(64, (3, 3), activation='linear', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='same', data_format=None))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='linear', input_shape=input_shape, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Conv2D(64, (3, 3), activation='linear', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='same', data_format=None))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='linear', input_shape=input_shape, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Conv2D(128, (3, 3), activation='linear', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='same', data_format=None))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='linear', input_shape=input_shape, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Conv2D(128, (3, 3), activation='linear', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='same', data_format=None))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(2048, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "225/224 [==============================] - 16s 73ms/step - loss: 2.0336 - acc: 0.2289 - val_loss: 2.0338 - val_acc: 0.1718\n",
      "Epoch 2/250\n",
      "225/224 [==============================] - 14s 63ms/step - loss: 1.9256 - acc: 0.2422 - val_loss: 1.7768 - val_acc: 0.2556\n",
      "Epoch 3/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.8995 - acc: 0.2539 - val_loss: 1.8288 - val_acc: 0.2509\n",
      "Epoch 4/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.8736 - acc: 0.2664 - val_loss: 1.8297 - val_acc: 0.2042\n",
      "Epoch 5/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.8625 - acc: 0.2723 - val_loss: 2.4757 - val_acc: 0.2517\n",
      "Epoch 6/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.8193 - acc: 0.2932 - val_loss: 6.6285 - val_acc: 0.1831\n",
      "Epoch 7/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.7780 - acc: 0.3070 - val_loss: 1.9381 - val_acc: 0.2644\n",
      "Epoch 8/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.7486 - acc: 0.3243 - val_loss: 1.7104 - val_acc: 0.3214\n",
      "Epoch 9/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.7335 - acc: 0.3385 - val_loss: 1.6715 - val_acc: 0.3408\n",
      "Epoch 10/250\n",
      "225/224 [==============================] - 14s 63ms/step - loss: 1.7065 - acc: 0.3497 - val_loss: 3.0060 - val_acc: 0.2604\n",
      "Epoch 11/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.6793 - acc: 0.3589 - val_loss: 1.7858 - val_acc: 0.3849\n",
      "Epoch 12/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.6212 - acc: 0.3899 - val_loss: 1.8741 - val_acc: 0.3508\n",
      "Epoch 13/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.5952 - acc: 0.4027 - val_loss: 1.7120 - val_acc: 0.3059\n",
      "Epoch 14/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.5508 - acc: 0.4167 - val_loss: 1.4184 - val_acc: 0.4753\n",
      "Epoch 15/250\n",
      "225/224 [==============================] - 15s 65ms/step - loss: 1.5056 - acc: 0.4315 - val_loss: 1.6280 - val_acc: 0.4218\n",
      "Epoch 16/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.5023 - acc: 0.4390 - val_loss: 1.9099 - val_acc: 0.3975\n",
      "Epoch 17/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.4967 - acc: 0.4425 - val_loss: 1.4348 - val_acc: 0.4468\n",
      "Epoch 18/250\n",
      "225/224 [==============================] - 15s 65ms/step - loss: 1.4773 - acc: 0.4472 - val_loss: 1.4112 - val_acc: 0.4578\n",
      "Epoch 19/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.4411 - acc: 0.4594 - val_loss: 1.2731 - val_acc: 0.5123\n",
      "Epoch 20/250\n",
      "225/224 [==============================] - 15s 65ms/step - loss: 1.3745 - acc: 0.4776 - val_loss: 1.2897 - val_acc: 0.5121\n",
      "Epoch 21/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.3488 - acc: 0.4881 - val_loss: 1.2985 - val_acc: 0.4962\n",
      "Epoch 22/250\n",
      "225/224 [==============================] - 15s 65ms/step - loss: 1.3321 - acc: 0.4914 - val_loss: 1.2223 - val_acc: 0.5242\n",
      "Epoch 23/250\n",
      "225/224 [==============================] - 15s 64ms/step - loss: 1.3191 - acc: 0.5004 - val_loss: 1.2791 - val_acc: 0.5089\n",
      "Epoch 24/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.3036 - acc: 0.5045 - val_loss: 1.2347 - val_acc: 0.5313\n",
      "Epoch 25/250\n",
      "225/224 [==============================] - 15s 65ms/step - loss: 1.2946 - acc: 0.5092 - val_loss: 1.1741 - val_acc: 0.5553\n",
      "Epoch 26/250\n",
      "225/224 [==============================] - 15s 65ms/step - loss: 1.2803 - acc: 0.5137 - val_loss: 1.1980 - val_acc: 0.5476\n",
      "Epoch 27/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.2678 - acc: 0.5205 - val_loss: 1.2137 - val_acc: 0.5295\n",
      "Epoch 28/250\n",
      "225/224 [==============================] - 14s 64ms/step - loss: 1.2672 - acc: 0.5228 - val_loss: 1.2055 - val_acc: 0.5378\n",
      "Epoch 29/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.2547 - acc: 0.5256 - val_loss: 1.1229 - val_acc: 0.5755\n",
      "Epoch 30/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.2584 - acc: 0.5242 - val_loss: 1.1269 - val_acc: 0.5727\n",
      "Epoch 31/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.2448 - acc: 0.5292 - val_loss: 1.1772 - val_acc: 0.5557\n",
      "Epoch 32/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.2445 - acc: 0.5284 - val_loss: 1.4901 - val_acc: 0.4815\n",
      "Epoch 33/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.2330 - acc: 0.5335 - val_loss: 1.1569 - val_acc: 0.5751\n",
      "Epoch 34/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.2210 - acc: 0.5398 - val_loss: 1.1487 - val_acc: 0.5613\n",
      "Epoch 35/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.2187 - acc: 0.5385 - val_loss: 1.1153 - val_acc: 0.5733\n",
      "Epoch 36/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.2159 - acc: 0.5372 - val_loss: 1.1758 - val_acc: 0.5557\n",
      "Epoch 37/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.2057 - acc: 0.5407 - val_loss: 1.3008 - val_acc: 0.5254\n",
      "Epoch 38/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.1987 - acc: 0.5508 - val_loss: 1.2601 - val_acc: 0.5454\n",
      "Epoch 39/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.2101 - acc: 0.5454 - val_loss: 1.1346 - val_acc: 0.5722\n",
      "Epoch 40/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.2001 - acc: 0.5440 - val_loss: 1.5310 - val_acc: 0.5535\n",
      "Epoch 41/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1887 - acc: 0.5517 - val_loss: 1.1145 - val_acc: 0.5755\n",
      "Epoch 42/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1836 - acc: 0.5516 - val_loss: 1.0676 - val_acc: 0.5926\n",
      "Epoch 43/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1822 - acc: 0.5549 - val_loss: 1.1559 - val_acc: 0.5624\n",
      "Epoch 44/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1683 - acc: 0.5589 - val_loss: 1.1011 - val_acc: 0.5899\n",
      "Epoch 45/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1684 - acc: 0.5578 - val_loss: 1.1450 - val_acc: 0.5726\n",
      "Epoch 46/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1655 - acc: 0.5637 - val_loss: 1.0670 - val_acc: 0.6009\n",
      "Epoch 47/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.1598 - acc: 0.5617 - val_loss: 1.1236 - val_acc: 0.5794\n",
      "Epoch 48/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1599 - acc: 0.5630 - val_loss: 1.0973 - val_acc: 0.5882\n",
      "Epoch 49/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1640 - acc: 0.5612 - val_loss: 1.0812 - val_acc: 0.5936\n",
      "Epoch 50/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1546 - acc: 0.5628 - val_loss: 1.1222 - val_acc: 0.5910\n",
      "Epoch 51/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1496 - acc: 0.5683 - val_loss: 1.3153 - val_acc: 0.5655\n",
      "Epoch 52/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1480 - acc: 0.5664 - val_loss: 1.1177 - val_acc: 0.5738\n",
      "Epoch 53/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1486 - acc: 0.5695 - val_loss: 1.0656 - val_acc: 0.5972\n",
      "Epoch 54/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1350 - acc: 0.5692 - val_loss: 1.0708 - val_acc: 0.5899\n",
      "Epoch 55/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1726 - acc: 0.5568 - val_loss: 1.0643 - val_acc: 0.6067\n",
      "Epoch 56/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1424 - acc: 0.5705 - val_loss: 1.0512 - val_acc: 0.6078\n",
      "Epoch 57/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1359 - acc: 0.5707 - val_loss: 1.0888 - val_acc: 0.6027\n",
      "Epoch 58/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1291 - acc: 0.5750 - val_loss: 1.0443 - val_acc: 0.6082\n",
      "Epoch 59/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1247 - acc: 0.5775 - val_loss: 1.1078 - val_acc: 0.5847\n",
      "Epoch 60/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1251 - acc: 0.5744 - val_loss: 1.0261 - val_acc: 0.6181\n",
      "Epoch 61/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1173 - acc: 0.5777 - val_loss: 1.0861 - val_acc: 0.6041\n",
      "Epoch 62/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.1215 - acc: 0.5754 - val_loss: 1.0497 - val_acc: 0.6063\n",
      "Epoch 63/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.1118 - acc: 0.5801 - val_loss: 1.1789 - val_acc: 0.5690\n",
      "Epoch 64/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1156 - acc: 0.5814 - val_loss: 1.0673 - val_acc: 0.5942\n",
      "Epoch 65/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1092 - acc: 0.5822 - val_loss: 1.0970 - val_acc: 0.6003\n",
      "Epoch 66/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1074 - acc: 0.5807 - val_loss: 1.0701 - val_acc: 0.6101\n",
      "Epoch 67/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1046 - acc: 0.5855 - val_loss: 1.0275 - val_acc: 0.6232\n",
      "Epoch 68/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1042 - acc: 0.5866 - val_loss: 1.0264 - val_acc: 0.6179\n",
      "Epoch 69/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1042 - acc: 0.5836 - val_loss: 1.0503 - val_acc: 0.6127\n",
      "Epoch 70/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.0959 - acc: 0.5874 - val_loss: 1.0086 - val_acc: 0.6236\n",
      "Epoch 71/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1029 - acc: 0.5838 - val_loss: 1.0157 - val_acc: 0.6254\n",
      "Epoch 72/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.1091 - acc: 0.5840 - val_loss: 1.0999 - val_acc: 0.5867\n",
      "Epoch 73/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0995 - acc: 0.5856 - val_loss: 0.9941 - val_acc: 0.6227\n",
      "Epoch 74/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0853 - acc: 0.5868 - val_loss: 1.0485 - val_acc: 0.6078\n",
      "Epoch 75/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0867 - acc: 0.5900 - val_loss: 1.0353 - val_acc: 0.6084\n",
      "Epoch 76/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0971 - acc: 0.5886 - val_loss: 1.0380 - val_acc: 0.6124\n",
      "Epoch 77/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0806 - acc: 0.5959 - val_loss: 1.0330 - val_acc: 0.6116\n",
      "Epoch 78/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0870 - acc: 0.5921 - val_loss: 1.0299 - val_acc: 0.6240\n",
      "Epoch 79/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0794 - acc: 0.5911 - val_loss: 1.0423 - val_acc: 0.6135\n",
      "Epoch 80/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0763 - acc: 0.5917 - val_loss: 1.1263 - val_acc: 0.5946\n",
      "Epoch 81/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0729 - acc: 0.5961 - val_loss: 1.0063 - val_acc: 0.6271\n",
      "Epoch 82/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 1.0762 - acc: 0.5940 - val_loss: 1.0974 - val_acc: 0.6060\n",
      "Epoch 83/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0729 - acc: 0.5954 - val_loss: 1.0585 - val_acc: 0.6202\n",
      "Epoch 84/250\n",
      "225/224 [==============================] - 15s 66ms/step - loss: 1.0697 - acc: 0.5964 - val_loss: 1.0932 - val_acc: 0.6076\n",
      "Epoch 85/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0683 - acc: 0.5968 - val_loss: 1.0653 - val_acc: 0.6057\n",
      "Epoch 86/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0827 - acc: 0.5915 - val_loss: 0.9955 - val_acc: 0.6350\n",
      "Epoch 87/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0680 - acc: 0.5978 - val_loss: 1.0372 - val_acc: 0.6085\n",
      "Epoch 88/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0667 - acc: 0.6008 - val_loss: 1.0335 - val_acc: 0.6290\n",
      "Epoch 89/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0627 - acc: 0.5956 - val_loss: 1.1024 - val_acc: 0.6009\n",
      "Epoch 90/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0670 - acc: 0.5968 - val_loss: 1.0399 - val_acc: 0.6135\n",
      "Epoch 91/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0568 - acc: 0.6025 - val_loss: 1.0169 - val_acc: 0.6137\n",
      "Epoch 92/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0564 - acc: 0.6027 - val_loss: 1.1183 - val_acc: 0.5932\n",
      "Epoch 93/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0547 - acc: 0.6012 - val_loss: 1.0052 - val_acc: 0.6279\n",
      "Epoch 94/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0591 - acc: 0.6010 - val_loss: 1.0121 - val_acc: 0.6280\n",
      "Epoch 95/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0552 - acc: 0.6056 - val_loss: 1.0401 - val_acc: 0.6220\n",
      "Epoch 96/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0487 - acc: 0.6033 - val_loss: 1.0181 - val_acc: 0.6273\n",
      "Epoch 97/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0504 - acc: 0.6045 - val_loss: 0.9904 - val_acc: 0.6305\n",
      "Epoch 98/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0502 - acc: 0.6052 - val_loss: 1.1709 - val_acc: 0.5940\n",
      "Epoch 99/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0450 - acc: 0.6069 - val_loss: 1.0128 - val_acc: 0.6258\n",
      "Epoch 100/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0466 - acc: 0.6041 - val_loss: 0.9646 - val_acc: 0.6470\n",
      "Epoch 101/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0462 - acc: 0.6075 - val_loss: 1.0068 - val_acc: 0.6343\n",
      "Epoch 102/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 1.0485 - acc: 0.6028 - val_loss: 1.0056 - val_acc: 0.6259\n",
      "Epoch 103/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0360 - acc: 0.6092 - val_loss: 0.9836 - val_acc: 0.6383\n",
      "Epoch 104/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0397 - acc: 0.6079 - val_loss: 1.0417 - val_acc: 0.6095\n",
      "Epoch 105/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0495 - acc: 0.6021 - val_loss: 1.0426 - val_acc: 0.6190\n",
      "Epoch 106/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0389 - acc: 0.6088 - val_loss: 1.0159 - val_acc: 0.6219\n",
      "Epoch 107/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0364 - acc: 0.6115 - val_loss: 1.0046 - val_acc: 0.6314\n",
      "Epoch 108/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 1.0259 - acc: 0.6141 - val_loss: 0.9912 - val_acc: 0.6305\n",
      "Epoch 109/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0384 - acc: 0.6074 - val_loss: 0.9828 - val_acc: 0.6354\n",
      "Epoch 110/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0444 - acc: 0.6062 - val_loss: 0.9857 - val_acc: 0.6400\n",
      "Epoch 111/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0510 - acc: 0.6074 - val_loss: 0.9877 - val_acc: 0.6322\n",
      "Epoch 112/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0265 - acc: 0.6138 - val_loss: 0.9809 - val_acc: 0.6425\n",
      "Epoch 113/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0310 - acc: 0.6113 - val_loss: 1.0321 - val_acc: 0.6280\n",
      "Epoch 114/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0286 - acc: 0.6101 - val_loss: 0.9802 - val_acc: 0.6344\n",
      "Epoch 115/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0262 - acc: 0.6131 - val_loss: 0.9943 - val_acc: 0.6379\n",
      "Epoch 116/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0225 - acc: 0.6136 - val_loss: 0.9510 - val_acc: 0.6464\n",
      "Epoch 117/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0196 - acc: 0.6177 - val_loss: 0.9814 - val_acc: 0.6310\n",
      "Epoch 118/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0225 - acc: 0.6152 - val_loss: 0.9949 - val_acc: 0.6280\n",
      "Epoch 119/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0571 - acc: 0.6018 - val_loss: 1.0938 - val_acc: 0.5907\n",
      "Epoch 120/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0360 - acc: 0.6130 - val_loss: 0.9945 - val_acc: 0.6283\n",
      "Epoch 121/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0208 - acc: 0.6166 - val_loss: 0.9497 - val_acc: 0.6453\n",
      "Epoch 122/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0195 - acc: 0.6164 - val_loss: 1.0051 - val_acc: 0.6336\n",
      "Epoch 123/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0091 - acc: 0.6193 - val_loss: 0.9872 - val_acc: 0.6322\n",
      "Epoch 124/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0108 - acc: 0.6198 - val_loss: 0.9693 - val_acc: 0.6372\n",
      "Epoch 125/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0113 - acc: 0.6184 - val_loss: 0.9781 - val_acc: 0.6358\n",
      "Epoch 126/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0019 - acc: 0.6232 - val_loss: 0.9891 - val_acc: 0.6369\n",
      "Epoch 127/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 1.0024 - acc: 0.6216 - val_loss: 0.9647 - val_acc: 0.6418\n",
      "Epoch 128/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0024 - acc: 0.6239 - val_loss: 0.9461 - val_acc: 0.6544\n",
      "Epoch 129/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0044 - acc: 0.6219 - val_loss: 0.9807 - val_acc: 0.6381\n",
      "Epoch 130/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0025 - acc: 0.6198 - val_loss: 1.0837 - val_acc: 0.6081\n",
      "Epoch 131/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0076 - acc: 0.6214 - val_loss: 0.9984 - val_acc: 0.6319\n",
      "Epoch 132/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0027 - acc: 0.6217 - val_loss: 0.9906 - val_acc: 0.6404\n",
      "Epoch 133/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9990 - acc: 0.6258 - val_loss: 0.9757 - val_acc: 0.6356\n",
      "Epoch 134/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9987 - acc: 0.6239 - val_loss: 1.0128 - val_acc: 0.6360\n",
      "Epoch 135/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0003 - acc: 0.6236 - val_loss: 0.9816 - val_acc: 0.6286\n",
      "Epoch 136/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0269 - acc: 0.6141 - val_loss: 0.9486 - val_acc: 0.6558\n",
      "Epoch 137/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9993 - acc: 0.6243 - val_loss: 0.9590 - val_acc: 0.6524\n",
      "Epoch 138/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9951 - acc: 0.6249 - val_loss: 0.9699 - val_acc: 0.6393\n",
      "Epoch 139/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9935 - acc: 0.6288 - val_loss: 0.9886 - val_acc: 0.6434\n",
      "Epoch 140/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9943 - acc: 0.6268 - val_loss: 0.9963 - val_acc: 0.6403\n",
      "Epoch 141/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9969 - acc: 0.6254 - val_loss: 0.9813 - val_acc: 0.6329\n",
      "Epoch 142/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9861 - acc: 0.6296 - val_loss: 0.9436 - val_acc: 0.6509\n",
      "Epoch 143/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9858 - acc: 0.6292 - val_loss: 0.9924 - val_acc: 0.6425\n",
      "Epoch 144/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9882 - acc: 0.6255 - val_loss: 0.9573 - val_acc: 0.6413\n",
      "Epoch 145/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9920 - acc: 0.6284 - val_loss: 0.9750 - val_acc: 0.6454\n",
      "Epoch 146/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9919 - acc: 0.6270 - val_loss: 0.9646 - val_acc: 0.6523\n",
      "Epoch 147/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9906 - acc: 0.6256 - val_loss: 0.9641 - val_acc: 0.6408\n",
      "Epoch 148/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 1.0106 - acc: 0.6222 - val_loss: 0.9994 - val_acc: 0.6375\n",
      "Epoch 149/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9918 - acc: 0.6304 - val_loss: 0.9926 - val_acc: 0.6435\n",
      "Epoch 150/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9792 - acc: 0.6306 - val_loss: 0.9657 - val_acc: 0.6429\n",
      "Epoch 151/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9795 - acc: 0.6278 - val_loss: 1.0009 - val_acc: 0.6328\n",
      "Epoch 152/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9912 - acc: 0.6282 - val_loss: 0.9631 - val_acc: 0.6493\n",
      "Epoch 153/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9817 - acc: 0.6352 - val_loss: 0.9666 - val_acc: 0.6442\n",
      "Epoch 154/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9809 - acc: 0.6310 - val_loss: 0.9534 - val_acc: 0.6549\n",
      "Epoch 155/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9820 - acc: 0.6312 - val_loss: 0.9250 - val_acc: 0.6569\n",
      "Epoch 156/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9796 - acc: 0.6306 - val_loss: 0.9534 - val_acc: 0.6502\n",
      "Epoch 157/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9750 - acc: 0.6337 - val_loss: 0.9605 - val_acc: 0.6532\n",
      "Epoch 158/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9793 - acc: 0.6303 - val_loss: 0.9553 - val_acc: 0.6576\n",
      "Epoch 159/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9812 - acc: 0.6302 - val_loss: 0.9427 - val_acc: 0.6565\n",
      "Epoch 160/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9849 - acc: 0.6286 - val_loss: 1.0101 - val_acc: 0.6191\n",
      "Epoch 161/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9834 - acc: 0.6301 - val_loss: 0.9524 - val_acc: 0.6534\n",
      "Epoch 162/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9735 - acc: 0.6307 - val_loss: 0.9367 - val_acc: 0.6597\n",
      "Epoch 163/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9719 - acc: 0.6347 - val_loss: 0.9819 - val_acc: 0.6478\n",
      "Epoch 164/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9750 - acc: 0.6335 - val_loss: 1.0396 - val_acc: 0.6140\n",
      "Epoch 165/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9795 - acc: 0.6294 - val_loss: 0.9540 - val_acc: 0.6496\n",
      "Epoch 166/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9692 - acc: 0.6363 - val_loss: 0.9463 - val_acc: 0.6467\n",
      "Epoch 167/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9729 - acc: 0.6304 - val_loss: 0.9782 - val_acc: 0.6322\n",
      "Epoch 168/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9687 - acc: 0.6358 - val_loss: 0.9610 - val_acc: 0.6470\n",
      "Epoch 169/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9693 - acc: 0.6368 - val_loss: 0.9636 - val_acc: 0.6471\n",
      "Epoch 170/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9633 - acc: 0.6348 - val_loss: 0.9433 - val_acc: 0.6565\n",
      "Epoch 171/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9672 - acc: 0.6327 - val_loss: 0.9733 - val_acc: 0.6385\n",
      "Epoch 172/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9637 - acc: 0.6369 - val_loss: 0.9579 - val_acc: 0.6546\n",
      "Epoch 173/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9616 - acc: 0.6344 - val_loss: 0.9919 - val_acc: 0.6453\n",
      "Epoch 174/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9648 - acc: 0.6376 - val_loss: 1.0001 - val_acc: 0.6293\n",
      "Epoch 175/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9666 - acc: 0.6372 - val_loss: 0.9634 - val_acc: 0.6468\n",
      "Epoch 176/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9668 - acc: 0.6355 - val_loss: 0.9517 - val_acc: 0.6475\n",
      "Epoch 177/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9585 - acc: 0.6393 - val_loss: 0.9358 - val_acc: 0.6633\n",
      "Epoch 178/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9577 - acc: 0.6410 - val_loss: 0.9470 - val_acc: 0.6546\n",
      "Epoch 179/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9658 - acc: 0.6371 - val_loss: 0.9999 - val_acc: 0.6396\n",
      "Epoch 180/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9569 - acc: 0.6406 - val_loss: 0.9796 - val_acc: 0.6512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9489 - acc: 0.6409 - val_loss: 0.9309 - val_acc: 0.6587\n",
      "Epoch 182/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9570 - acc: 0.6410 - val_loss: 0.9323 - val_acc: 0.6651\n",
      "Epoch 183/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9549 - acc: 0.6393 - val_loss: 0.9960 - val_acc: 0.6434\n",
      "Epoch 184/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9571 - acc: 0.6421 - val_loss: 0.9755 - val_acc: 0.6530\n",
      "Epoch 185/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9621 - acc: 0.6405 - val_loss: 0.9335 - val_acc: 0.6580\n",
      "Epoch 186/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9512 - acc: 0.6399 - val_loss: 0.9408 - val_acc: 0.6513\n",
      "Epoch 187/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9553 - acc: 0.6379 - val_loss: 1.0227 - val_acc: 0.6234\n",
      "Epoch 188/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9596 - acc: 0.6385 - val_loss: 0.9769 - val_acc: 0.6467\n",
      "Epoch 189/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9532 - acc: 0.6394 - val_loss: 0.9389 - val_acc: 0.6565\n",
      "Epoch 190/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9519 - acc: 0.6416 - val_loss: 0.9294 - val_acc: 0.6595\n",
      "Epoch 191/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9485 - acc: 0.6437 - val_loss: 0.9373 - val_acc: 0.6530\n",
      "Epoch 192/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9464 - acc: 0.6429 - val_loss: 0.9694 - val_acc: 0.6510\n",
      "Epoch 193/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9556 - acc: 0.6404 - val_loss: 0.9503 - val_acc: 0.6484\n",
      "Epoch 194/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9647 - acc: 0.6365 - val_loss: 0.9691 - val_acc: 0.6457\n",
      "Epoch 195/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9437 - acc: 0.6448 - val_loss: 0.9659 - val_acc: 0.6520\n",
      "Epoch 196/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9445 - acc: 0.6436 - val_loss: 0.9796 - val_acc: 0.6573\n",
      "Epoch 197/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9438 - acc: 0.6461 - val_loss: 0.9207 - val_acc: 0.6627\n",
      "Epoch 198/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9411 - acc: 0.6475 - val_loss: 0.9309 - val_acc: 0.6587\n",
      "Epoch 199/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9428 - acc: 0.6463 - val_loss: 1.0088 - val_acc: 0.6272\n",
      "Epoch 200/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9398 - acc: 0.6478 - val_loss: 1.0468 - val_acc: 0.6340\n",
      "Epoch 201/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9451 - acc: 0.6450 - val_loss: 0.9387 - val_acc: 0.6552\n",
      "Epoch 202/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9409 - acc: 0.6483 - val_loss: 0.9576 - val_acc: 0.6574\n",
      "Epoch 203/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9408 - acc: 0.6450 - val_loss: 0.9415 - val_acc: 0.6590\n",
      "Epoch 204/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9329 - acc: 0.6464 - val_loss: 0.9236 - val_acc: 0.6641\n",
      "Epoch 205/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9316 - acc: 0.6463 - val_loss: 0.9494 - val_acc: 0.6500\n",
      "Epoch 206/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9378 - acc: 0.6469 - val_loss: 1.0117 - val_acc: 0.6330\n",
      "Epoch 207/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9504 - acc: 0.6429 - val_loss: 0.9486 - val_acc: 0.6658\n",
      "Epoch 208/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9385 - acc: 0.6482 - val_loss: 0.9382 - val_acc: 0.6587\n",
      "Epoch 209/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9396 - acc: 0.6475 - val_loss: 0.9663 - val_acc: 0.6389\n",
      "Epoch 210/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9349 - acc: 0.6490 - val_loss: 0.9279 - val_acc: 0.6598\n",
      "Epoch 211/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9312 - acc: 0.6478 - val_loss: 0.9045 - val_acc: 0.6648\n",
      "Epoch 212/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9342 - acc: 0.6483 - val_loss: 0.9373 - val_acc: 0.6644\n",
      "Epoch 213/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9323 - acc: 0.6484 - val_loss: 0.9508 - val_acc: 0.6598\n",
      "Epoch 214/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9334 - acc: 0.6506 - val_loss: 0.9676 - val_acc: 0.6509\n",
      "Epoch 215/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9257 - acc: 0.6516 - val_loss: 0.9793 - val_acc: 0.6491\n",
      "Epoch 216/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9245 - acc: 0.6530 - val_loss: 0.9325 - val_acc: 0.6610\n",
      "Epoch 217/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9302 - acc: 0.6487 - val_loss: 1.0447 - val_acc: 0.6124\n",
      "Epoch 218/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9235 - acc: 0.6511 - val_loss: 0.9405 - val_acc: 0.6585\n",
      "Epoch 219/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9321 - acc: 0.6520 - val_loss: 0.9758 - val_acc: 0.6464\n",
      "Epoch 220/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9265 - acc: 0.6509 - val_loss: 0.9167 - val_acc: 0.6610\n",
      "Epoch 221/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9236 - acc: 0.6523 - val_loss: 0.9300 - val_acc: 0.6636\n",
      "Epoch 222/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9353 - acc: 0.6509 - val_loss: 0.9770 - val_acc: 0.6421\n",
      "Epoch 223/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9252 - acc: 0.6541 - val_loss: 0.9433 - val_acc: 0.6647\n",
      "Epoch 224/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9297 - acc: 0.6510 - val_loss: 0.9456 - val_acc: 0.6542\n",
      "Epoch 225/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9259 - acc: 0.6513 - val_loss: 0.9510 - val_acc: 0.6553\n",
      "Epoch 226/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9218 - acc: 0.6532 - val_loss: 0.9224 - val_acc: 0.6701\n",
      "Epoch 227/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9250 - acc: 0.6553 - val_loss: 0.9297 - val_acc: 0.6638\n",
      "Epoch 228/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9202 - acc: 0.6554 - val_loss: 0.9812 - val_acc: 0.6333\n",
      "Epoch 229/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9182 - acc: 0.6558 - val_loss: 0.9540 - val_acc: 0.6595\n",
      "Epoch 230/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9177 - acc: 0.6567 - val_loss: 0.9316 - val_acc: 0.6578\n",
      "Epoch 231/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9186 - acc: 0.6550 - val_loss: 0.9917 - val_acc: 0.6385\n",
      "Epoch 232/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9207 - acc: 0.6539 - val_loss: 0.9326 - val_acc: 0.6617\n",
      "Epoch 233/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9214 - acc: 0.6542 - val_loss: 0.9542 - val_acc: 0.6491\n",
      "Epoch 234/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9147 - acc: 0.6575 - val_loss: 0.9411 - val_acc: 0.6584\n",
      "Epoch 235/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9109 - acc: 0.6573 - val_loss: 0.9544 - val_acc: 0.6606\n",
      "Epoch 236/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9153 - acc: 0.6529 - val_loss: 0.9428 - val_acc: 0.6553\n",
      "Epoch 237/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9248 - acc: 0.6533 - val_loss: 0.9640 - val_acc: 0.6626\n",
      "Epoch 238/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9169 - acc: 0.6561 - val_loss: 0.9159 - val_acc: 0.6702\n",
      "Epoch 239/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9124 - acc: 0.6567 - val_loss: 0.9196 - val_acc: 0.6661\n",
      "Epoch 240/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9327 - acc: 0.6448 - val_loss: 0.9291 - val_acc: 0.6663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9163 - acc: 0.6598 - val_loss: 0.9290 - val_acc: 0.6680\n",
      "Epoch 242/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9137 - acc: 0.6561 - val_loss: 0.9293 - val_acc: 0.6594\n",
      "Epoch 243/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9159 - acc: 0.6544 - val_loss: 0.9263 - val_acc: 0.6620\n",
      "Epoch 244/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9099 - acc: 0.6571 - val_loss: 0.9370 - val_acc: 0.6608\n",
      "Epoch 245/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9124 - acc: 0.6587 - val_loss: 0.9421 - val_acc: 0.6649\n",
      "Epoch 246/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9117 - acc: 0.6570 - val_loss: 0.9356 - val_acc: 0.6570\n",
      "Epoch 247/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9086 - acc: 0.6612 - val_loss: 0.9205 - val_acc: 0.6641\n",
      "Epoch 248/250\n",
      "225/224 [==============================] - 15s 68ms/step - loss: 0.9162 - acc: 0.6558 - val_loss: 0.9601 - val_acc: 0.6527\n",
      "Epoch 249/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9108 - acc: 0.6594 - val_loss: 0.9302 - val_acc: 0.6673\n",
      "Epoch 250/250\n",
      "225/224 [==============================] - 15s 67ms/step - loss: 0.9088 - acc: 0.6616 - val_loss: 0.9297 - val_acc: 0.6599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0980045a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, \n",
    "                             height_shift_range=0.2, shear_range=0.2, \n",
    "                             zoom_range=0.2, horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "datagen.fit(x_train)\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch=len(x_train) / 128, verbose=1, epochs=250, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc0e00b1f8e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n\u001b[0m\u001b[1;32m      2\u001b[0m                     steps_per_epoch=len(x_train) / 128, verbose=1, epochs=1, validation_data=(x_val, y_val))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch=len(x_train) / 128, verbose=1, epochs=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.save('two.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = read_test_data(test_data_path)\n",
    "x_test = np.array(x_test).reshape(np.array(x_test).shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "pred = model.predict(x_val)\n",
    "print(pred) \n",
    "write_answer(answer_path, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
