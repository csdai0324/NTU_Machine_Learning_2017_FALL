{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_num = 18\n",
    "feature_list = ['AMB_TEMP', 'CH4', 'CO', 'NMHC', 'NO', 'NO2', 'NOx',\n",
    "                'O3','PM10', 'PM2.5', 'RAINFALL', 'RH', 'SO2', 'THC',\n",
    "                'WD_HR', 'WIND_DIREC', 'WIND_SPEED', 'WS_HR']\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "output_answer_path = './answer.csv'\n",
    "\n",
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, location, date, feature_dict):\n",
    "        \n",
    "        self.location = location\n",
    "        self.date = date\n",
    "        self.feature_dict = feature_dict\n",
    "        self.str2num()\n",
    "        self.PM2point5 = self.feature_dict['PM2.5']\n",
    "        \n",
    "    def str2num(self):   \n",
    "        for feature in feature_list:\n",
    "            if feature == 'RAINFALL':\n",
    "                temp = self.feature_dict[feature]\n",
    "                for i in range(len(temp)):\n",
    "                    if self.feature_dict[feature][i] == 'NR':\n",
    "                        self.feature_dict[feature][i] = 1.\n",
    "                    else:\n",
    "                        self.feature_dict[feature][i] = 1.01\n",
    "                self.feature_dict[feature] = np.array(self.feature_dict[feature])\n",
    "                continue\n",
    "            temp = self.feature_dict[feature]\n",
    "            for i in range(len(temp)):\n",
    "                self.feature_dict[feature][i] = float(temp[i])\n",
    "            self.feature_dict[feature] = np.array(self.feature_dict[feature])\n",
    "            \n",
    "    def feature2matrix(self):   \n",
    "        x = np.ndarray(shape=(18, 24), dtype=float)\n",
    "        cntr = 0\n",
    "        for feature in feature_list:\n",
    "            x[cntr] = self.feature_dict[feature]\n",
    "            cntr += 1\n",
    "            \n",
    "        return np.asmatrix(x)\n",
    "    \n",
    "    def test_feature2matrix(self):      \n",
    "        x = np.ndarray(shape=(18, 9), dtype=float)\n",
    "        cntr = 0\n",
    "        for feature in feature_list:\n",
    "            x[cntr] = self.feature_dict[feature]\n",
    "            cntr += 1\n",
    "            \n",
    "        return np.asmatrix(x)\n",
    "    \n",
    "    def get_matrix(self):\n",
    "        self.x = self.feature2matrix()\n",
    "        return self.x\n",
    "    \n",
    "    def test_get_matrix(self):\n",
    "        self.x = self.test_feature2matrix()\n",
    "        return self.x\n",
    "    \n",
    "    def get_PM2point5(self):\n",
    "        return self.PM2point5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def PM2point5_dataset(train_data_path):\n",
    "    train_data, feature_mean_dict, feature_std_dict = feature_scaling(read_train_data(train_data_path))\n",
    "    x_matrix = None\n",
    "    y_matrix = None\n",
    "    cntr = 0\n",
    "    for data in train_data:\n",
    "        if cntr == 0:\n",
    "            x_matrix = data.get_matrix()\n",
    "            y_matrix = data.get_PM2point5()\n",
    "            cntr += 1\n",
    "            continue\n",
    "        x_temp = data.get_matrix()\n",
    "        y_temp = data.get_PM2point5()\n",
    "        x_matrix = np.hstack((x_matrix, x_temp))\n",
    "        y_matrix = np.hstack((y_matrix, y_temp))\n",
    "        cntr += 1\n",
    "        \n",
    "    return x_matrix, y_matrix, feature_mean_dict, feature_std_dict\n",
    "\n",
    "def read_train_data(train_data_path):\n",
    "    train_data = []\n",
    "    feature_value = []\n",
    "    line_count = 0\n",
    "    \n",
    "    with open(train_data_path, encoding='big5') as train_data_csv:\n",
    "        next(train_data_csv)\n",
    "        reader = csv.reader(train_data_csv, delimiter=',')\n",
    "        for line in reader:\n",
    "            line_count += 1\n",
    "            time = line[0].split('/')\n",
    "            date = datetime.datetime(int(time[0]), int(time[1]), int(time[2]))\n",
    "            location = line[1].strip()\n",
    "            value = []\n",
    "            for ele in line[3:]:\n",
    "                value.append(ele)     \n",
    "            feature_value.append(value)\n",
    "            if line_count % 18 == 0:\n",
    "                feature_dict = dict(zip(feature_list, feature_value))\n",
    "                train_data.append(Data(location, date, feature_dict))\n",
    "                feature_value = []\n",
    "                \n",
    "    return train_data\n",
    "\n",
    "def read_test_data(test_data_path, feature_mean_dict, feature_std_dict):\n",
    "    test_data = []\n",
    "    feature_value = []\n",
    "    line_count = 0\n",
    "    with open(test_data_path, encoding='big5') as test_data_csv:\n",
    "        reader = csv.reader(test_data_csv, delimiter=',')\n",
    "        for line in reader:\n",
    "            line_count += 1\n",
    "            value = []\n",
    "            for ele in line[2:]:\n",
    "                value.append(ele)     \n",
    "            feature_value.append(value)\n",
    "            if line_count % 18 == 0:\n",
    "                feature_dict = dict(zip(feature_list, feature_value))\n",
    "                test_data.append(Data('', '0-0-0', feature_dict))\n",
    "                feature_value = [] \n",
    "                \n",
    "    for data in test_data:\n",
    "        for feature in feature_list:\n",
    "            data.feature_dict[feature] = (data.feature_dict[feature] - feature_mean_dict[feature]) / feature_std_dict[feature]\n",
    "                \n",
    "    return test_data\n",
    "\n",
    "def feature_scaling(train_data):  \n",
    "    feature_value = [np.array([])]*24\n",
    "    feature_dict = dict(zip(feature_list, feature_value))\n",
    "    feature_mean = []*24\n",
    "    feature_mean_dict = dict(zip(feature_list, feature_value))\n",
    "    feature_std = []*24\n",
    "    feature_std_dict = dict(zip(feature_list, feature_value)) \n",
    "    \n",
    "    for data in train_data:    \n",
    "        for feature in feature_list:\n",
    "            feature_dict[feature] = np.concatenate((feature_dict[feature], data.feature_dict[feature]))   \n",
    "    for feature in feature_list:    \n",
    "        if feature == 'RAINFALL':\n",
    "            feature_mean_dict[feature] = feature_dict[feature].mean()\n",
    "            feature_std_dict[feature] = feature_dict[feature].std()\n",
    "            continue\n",
    "        feature_mean_dict[feature] = feature_dict[feature].mean()\n",
    "        feature_std_dict[feature] = feature_dict[feature].std()\n",
    "    \n",
    "    feature_dict = dict(zip(feature_list, feature_value))\n",
    "    for data in train_data:\n",
    "        for feature in feature_list:\n",
    "            data.feature_dict[feature] = (data.feature_dict[feature] - feature_mean_dict[feature]) / feature_std_dict[feature]\n",
    "\n",
    "    return train_data, feature_mean_dict, feature_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def linear_regression_one(X, Y, hr, learning_rate):\n",
    "    iteration = 5000\n",
    "    W_b = np.random.rand(feature_num*hr+1) \n",
    "    y_len = X.shape[1] - hr\n",
    "    #print(count_loss(W_b, X, Y, hr))\n",
    "    for epoch in range(iteration):\n",
    "        if epoch % 10 == 0:\n",
    "            print('epoch:', (epoch+1), 'RMSD:', count_loss(W_b, X, Y, hr))\n",
    "            if (epoch+1) % 500 == 0:\n",
    "                print(list(W_b))\n",
    "        temp_W_b = W_b\n",
    "        for i in range(len(W_b)):\n",
    "            delta = 0\n",
    "            for cntr in range(y_len):\n",
    "                if (cntr + hr) % 480 == 0 and cntr is not 0:\n",
    "                    cntr += 10\n",
    "                x = np.concatenate((np.array(X[:,cntr:cntr+hr]).reshape(-1), [1]), axis=0)\n",
    "                delta += (np.dot(W_b, x) - Y[cntr+hr]) * x[i]\n",
    "            temp_W_b[i] = W_b[i] - learning_rate * (1 / y_len) * delta\n",
    "        W_b = temp_W_b\n",
    "        if epoch % 1000 == 0:\n",
    "            learning_rate *= 0.1\n",
    "            \n",
    "    return W_b\n",
    "\n",
    "def count_loss(W_b, X, Y, hr):\n",
    "    loss = 0.\n",
    "    y_len = X.shape[1] - hr\n",
    "    RMSE = 0.\n",
    "    for cntr in range(y_len):\n",
    "        if (cntr + hr) % 480 == 0 and cntr is not 0:   \n",
    "            cntr += 10\n",
    "        x = np.concatenate((np.array(X[:,cntr:cntr+hr]).reshape(-1), [1]), axis=0)\n",
    "        loss += ((np.dot(W_b, x)) - Y[cntr+hr])**2\n",
    "        \n",
    "    return math.sqrt(loss / (y_len))\n",
    "\n",
    "def test(test_data, W_b):\n",
    "    answer = []\n",
    "    for data in test_data:\n",
    "        x_matrix = data.test_get_matrix()\n",
    "        x_ = np.concatenate((np.array(x_matrix).reshape(-1), [1]), axis=0)\n",
    "        answer.append(np.dot(W_b, x_))\n",
    "    return answer\n",
    "\n",
    "def output_answer(output_answer_path, answer):\n",
    "    os.remove(output_answer_path)\n",
    "    with open(output_answer_path, 'a') as output_csv:\n",
    "        output_csv.write('id,value\\r\\n')\n",
    "        for i in range(len(answer)):\n",
    "            line = 'id%d,%f', (int(i+1), an)\n",
    "            output_csv.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 RMSD: 31.020275307047683\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'i' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-43dc0951d8c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mean_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_std_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPM2point5_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mean_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_std_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#W_b = [3.25108426e-01,-5.03398455e-01,-2.12642109e-01,6.68537231e-02,-2.72730167e-01,-6.66302095e-02,1.85388996e-01,6.48821276e-02,2.36598006e-01,-1.62021897e-01,3.20845117e-02,-2.04757765e-02,-2.08234699e-01,-1.31801358e-01,-1.89750931e-02,-6.15993875e-03,1.42570000e-02,2.10914480e-01,6.51178481e-02,-1.28857019e-02,7.44868267e-02,-1.22344642e-01,1.39808143e-01,-6.96903363e-02,-1.31240411e-01,9.38781660e-02,4.65731079e-01,-1.32497524e-01,2.91526300e-02,-7.61704817e-02,-1.06280952e-02,7.46664448e-02,-1.25409109e-01,3.25778129e-02,-1.70529749e-01,5.65749710e-02,5.67906514e-02,-2.09573119e-03,3.17513702e-01,-9.05480532e-02,-4.04705686e-02,-1.48390506e-02,1.11932375e-01,1.77284568e-01,-2.35969237e-01,-9.26590928e-02,-2.75119576e-01,-1.50227308e-01,-1.04311253e-01,-9.58637077e-02,-3.66456875e-03,-3.59957824e-01,-9.87228097e-02,1.39436250e+00,1.64920032e-01,-3.72694802e-02,-1.42860084e-01,1.00718618e-01,-4.69053027e-02,-3.62730866e-01,3.38637036e-02,9.77014653e-02,2.99827237e-01,7.06336195e-02,3.30077782e-01,-3.66359787e-01,-2.31700455e-01,-3.82260860e-01,-6.07540990e-01,-2.98363262e-01,2.17782023e-02,1.94458256e+00,-7.47271713e-02,2.21238650e-01,5.94980091e-02,1.68817360e-02,-3.19062333e-01,3.90150501e-01,-4.08573717e-01,-2.42064567e-01,2.06082202e+00,9.98575688e-02,1.23712109e-01,4.17649306e-01,-8.44007259e-02,7.61522167e-01,9.49880667e-01,-3.06834440e+00,2.42141250e+00,1.14885628e+01,-1.70068751e-02,-7.11624703e-02,2.47554673e-02,-8.46883923e-02,1.39972404e-01,9.95604226e-02,-9.61615908e-02,-1.85214841e-01,-2.45231917e-01,1.03753172e-01,1.95248674e-01,5.43848102e-02,-7.91315924e-01,-7.37131303e-02,1.70538896e-01,-4.90753973e-01,8.08942935e-02,4.80254732e-01,-3.14545607e-01,3.83013731e-01,-1.25946383e-01,-4.65914765e-02,-1.29954564e-02,1.26344279e-01,-2.56842769e-01,1.14801201e-01,4.89312914e-01,2.03971846e-01,-6.37071614e-02,6.90494170e-02,2.56330121e-02,1.91484885e-01,2.09936155e-01,-1.53807136e-01,-1.07224465e-01,3.15637654e-01,-3.72047807e-02,2.23722578e-01,-3.49814358e-02,2.55922124e-01,1.98226605e-02,1.03467887e-01,-2.19492449e-01,1.16948261e-01,5.05647635e-02,-1.31826912e-01,-6.56214189e-02,3.82886663e-02,-2.05315436e-01,1.51769955e-01,4.41706076e-02,-1.07322022e-01,-3.12404791e-01,8.99251586e-02,-1.68664504e-01,-6.53218148e-02,1.89773492e-01,4.32174107e-02,-1.14284463e-01,-1.55312526e-01,-1.16590130e-01,-4.79492754e-03,-4.46518539e-02,-3.57445454e-02,1.73002224e-01,-1.62926464e-01,-2.02160808e-01,1.05756336e-01,2.85947730e-01,-2.14610238e-02,-1.58448061e-01,1.48824633e-02,2.13961501e+01]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-fb8c2f30c21f>\u001b[0m in \u001b[0;36mlinear_regression_one\u001b[0;34m(X, Y, hr, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcntr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcntr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcntr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mdelta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcntr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#delta = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'i' referenced before assignment"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "hour = 9\n",
    "X, Y, feature_mean_dict, feature_std_dict = PM2point5_dataset(train_data_path)\n",
    "X_ = read_test_data(test_data_path, feature_mean_dict, feature_std_dict)\n",
    "W = linear_regression_one(X, Y, hour, learning_rate)\n",
    "#W_b = [3.25108426e-01,-5.03398455e-01,-2.12642109e-01,6.68537231e-02,-2.72730167e-01,-6.66302095e-02,1.85388996e-01,6.48821276e-02,2.36598006e-01,-1.62021897e-01,3.20845117e-02,-2.04757765e-02,-2.08234699e-01,-1.31801358e-01,-1.89750931e-02,-6.15993875e-03,1.42570000e-02,2.10914480e-01,6.51178481e-02,-1.28857019e-02,7.44868267e-02,-1.22344642e-01,1.39808143e-01,-6.96903363e-02,-1.31240411e-01,9.38781660e-02,4.65731079e-01,-1.32497524e-01,2.91526300e-02,-7.61704817e-02,-1.06280952e-02,7.46664448e-02,-1.25409109e-01,3.25778129e-02,-1.70529749e-01,5.65749710e-02,5.67906514e-02,-2.09573119e-03,3.17513702e-01,-9.05480532e-02,-4.04705686e-02,-1.48390506e-02,1.11932375e-01,1.77284568e-01,-2.35969237e-01,-9.26590928e-02,-2.75119576e-01,-1.50227308e-01,-1.04311253e-01,-9.58637077e-02,-3.66456875e-03,-3.59957824e-01,-9.87228097e-02,1.39436250e+00,1.64920032e-01,-3.72694802e-02,-1.42860084e-01,1.00718618e-01,-4.69053027e-02,-3.62730866e-01,3.38637036e-02,9.77014653e-02,2.99827237e-01,7.06336195e-02,3.30077782e-01,-3.66359787e-01,-2.31700455e-01,-3.82260860e-01,-6.07540990e-01,-2.98363262e-01,2.17782023e-02,1.94458256e+00,-7.47271713e-02,2.21238650e-01,5.94980091e-02,1.68817360e-02,-3.19062333e-01,3.90150501e-01,-4.08573717e-01,-2.42064567e-01,2.06082202e+00,9.98575688e-02,1.23712109e-01,4.17649306e-01,-8.44007259e-02,7.61522167e-01,9.49880667e-01,-3.06834440e+00,2.42141250e+00,1.14885628e+01,-1.70068751e-02,-7.11624703e-02,2.47554673e-02,-8.46883923e-02,1.39972404e-01,9.95604226e-02,-9.61615908e-02,-1.85214841e-01,-2.45231917e-01,1.03753172e-01,1.95248674e-01,5.43848102e-02,-7.91315924e-01,-7.37131303e-02,1.70538896e-01,-4.90753973e-01,8.08942935e-02,4.80254732e-01,-3.14545607e-01,3.83013731e-01,-1.25946383e-01,-4.65914765e-02,-1.29954564e-02,1.26344279e-01,-2.56842769e-01,1.14801201e-01,4.89312914e-01,2.03971846e-01,-6.37071614e-02,6.90494170e-02,2.56330121e-02,1.91484885e-01,2.09936155e-01,-1.53807136e-01,-1.07224465e-01,3.15637654e-01,-3.72047807e-02,2.23722578e-01,-3.49814358e-02,2.55922124e-01,1.98226605e-02,1.03467887e-01,-2.19492449e-01,1.16948261e-01,5.05647635e-02,-1.31826912e-01,-6.56214189e-02,3.82886663e-02,-2.05315436e-01,1.51769955e-01,4.41706076e-02,-1.07322022e-01,-3.12404791e-01,8.99251586e-02,-1.68664504e-01,-6.53218148e-02,1.89773492e-01,4.32174107e-02,-1.14284463e-01,-1.55312526e-01,-1.16590130e-01,-4.79492754e-03,-4.46518539e-02,-3.57445454e-02,1.73002224e-01,-1.62926464e-01,-2.02160808e-01,1.05756336e-01,2.85947730e-01,-2.14610238e-02,-1.58448061e-01,1.48824633e-02,2.13961501e+01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = test(X_, W_b)\n",
    "output_answer(output_answer_path, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
